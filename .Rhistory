# pbsapply(1:10, function(i) paste0(as.character(treetag(zh$ContextBefore[i],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass), collapse = " "))
# paste0(as.character(treetag(zh$ContextBefore[1],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass), collapse = " ")
# pbsapply(1:nrow(zh), function(i) treetag(zh$last_left[i],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass)
# zh_left_tags <- treetag(zh$last_left,
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")
# Chunk 10
# new column: "cxn" for "construction"
zh$cxn <- character(nrow(zh))
# von zu Hause
zh[which(zh$last_left=="von"),]$cxn <- "von zh"
# zu Hause zu V-en
zh[which(zh$first_right=="zu" & zh$cxn == ""),]$cxn <- "zh zu v"
# zu Hause sein
zh[which(zh$first_right %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart") | zh$last_left %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart")),]$cxn <- "zh sein"
# zh einsperren / eingesperrt
zh[grep("ein(ge)?sperr.*", zh$last_left),]$cxn <- "zh EINSPERR"
zh[grep("ein(ge)?sperr.*", zh$first_right),]$cxn <- "zh EINSPERR"
# zh verbringen
zh[grep("verbring|verbrach", zh$first_right),]$cxn <- "zh verbringen"
zh[grep("verbring|verbrach", zh$last_left),]$cxn <- "zh verbringen"
# das (eigene) Zuhause
zh[which(zh$last_left %in% c("das", "dem", "ein", "einem")),]$cxn <- "ART zh"
zh[which(last_left(zh, "ContextBefore", n = 2) %in% c("das eigene", "dem eigenen", "ein eigenes", "einem eigenen")),]$cxn <- "ART eigene zh"
# PRONOUN (demonstrative/possessive & quantifiers) + Zuhause
zh[which(zh$last_left %in% c("Ihr", "ihr", "sein", "dein", "mein", "unser", "euer", "seinem", "unserem", "keinem", "dieses", "dessen", "Ihrem", "ihrem", "kein", "keinem", "manches", "mehrere", "meinem")),]$cxn <- "PRONOUN zh"
# zh in Quarantäne
zh[which(first_right(zh, "ContextAfter", n = 2) == "in Quarantäne"),]$cxn <- "zh in Quarantäne"
# für zh
zh[which(zh$last_left == "für"),]$cxn <- "für zh"
# zh arbeiten
zh[grep("arbeit.*", zh$last_left),]$cxn <- "zh arbeiten"
zh[grep("arbeit.*", zh$first_right),]$cxn <- "zh arbeiten"
# zh bleiben
zh[grep("[Bb]leib.*", last_left(zh, "ContextBefore", n = 5)),]$cxn = "zh bleiben"
zh[grep("[Bb]leib.*", first_right(zh, "ContextAfter", n = 5)),]$cxn = "zh bleiben"
# Chunk 11: spl
set.seed(1985)
spl <- sample(1:nrow(zh), 2000)
zh$spl <- character(nrow(zh))
zh[spl,]$spl <- "in_sample"
# zh %>% write.xlsx("zh_spl.xlsx", overwrite = T)
# Chunk 12
# write.xlsx(zh, "zh.xlsx")
# Chunk 13
zh_anno <- read_xlsx("zh_spl_anno.xlsx")
# Chunk 14
zh_anno <- left_join(zh_anno, urls, by = c("URL" = "url"))
# Chunk 15
zh_anno <- filter(zh_anno, spl == "in_sample")
zh_anno <- filter(zh_anno, keep != "n")
# Chunk 16
qbarplot(zh_anno, cxn, Hit) + guides(fill = guide_legend(title = "Variant")) + theme(axis.text.x = element_text(angle=45, hjust=.9, size=12)) + xlab("Construction")
# Chunk 17
#export
# write_excel_csv(tibble(category = unique(zh$category),
#                        texttype = character(length(unique(zh$category)))),
#                 "texttypes.csv")
# re-import
texttype <- read_csv("texttypes.csv")
# bind with zh_anno
zh_anno <- left_join(zh_anno, texttype)
# convert response variable to factor
zh_anno$Hit <- factor(zh_anno$Hit)
zh_anno$cxn <- factor(zh_anno$cxn)
zh_anno$category <- factor(zh_anno$category)
zh_anno$texttype <- factor(zh_anno$texttype)
# get ctree
ct <- partykit::ctree(Hit ~ cxn + texttype, data = zh_anno)
cf <- cforest(Hit ~ cxn + texttype, data = zh_anno, controls = cforest_unbiased(mtry = 1))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 7),
ip_args=list(
abbreviate = TRUE))
?edge_simple
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 10),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 15),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 3),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 10),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 20),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 3),
ip_args=list(
abbreviate = TRUE))
?edge_simple
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 3, abbreviate = TRUE),
ip_args=list(
abbreviate = TRUE))
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 3),
ip_args=list(
abbreviate = TRUE, justmin = 15))
partykit::plot.party()
partykit::plot.party()
?partykit::plot.party()
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 6),
ip_args=list(
abbreviate = TRUE))
# random forest results
dotplot(cf)
# random forest results
cf
# random forest results
str(cf)
# random forest results
summary(cf)
# get variable importance
varimp <- varimp(cf, conditional = T)
# random forest results: conditional variable importance
dotplot(varimp)
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 6),
ip_args=list(
abbreviate = TRUE))
rm(list=ls())
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# install "concordances" package, if not yet installed
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# install "wizard" package, if not yet installed
if(!is.element("wizard", installed.packages())) {
devtools::install_github("hartmast/wizard")
}
library(tidyverse)
library("koRpus.lang.de")
library(scales)
library(concordances)
library(pbapply)
library(readxl)
library(openxlsx)
library(kableExtra)
library(party)
library(lattice)
library(mlogit)
library(wizard)
# Chunk 2
# read data
zuhause <- read_csv("zuhause_lowercase.csv", col_types = c("d", rep("c", 7)))
Zuhause <- read_csv("Zuhause.csv")
zu_Hause <- read_csv("zu_Hause.csv", col_types = c("d", rep("c", 7)))
# add Month and Year columns
zuhause$Month <- gsub("^[0-9]{4}-|-[0-9]{2}$", "", zuhause$Date)
zuhause$Year <- gsub("-.*", "", zuhause$Date)
zuhause$YM   <- paste0(zuhause$Year, "-", zuhause$Month)
zu_Hause$Year <- gsub(".*\\.", "", zu_Hause$Date)
zu_Hause$Month <- gsub("^[0-9]{2}\\.|\\.[0-9]{4}$", "", zu_Hause$Date)
zu_Hause$YM  <- paste0(zu_Hause$Year, "-", zu_Hause$Month)
Zuhause$Month <- gsub("^[0-9]{4}-|-[0-9]{2}$", "", Zuhause$Date)
Zuhause$Year <- gsub("-.*", "", Zuhause$Date)
Zuhause$YM   <- paste0(Zuhause$Year, "-", Zuhause$Month)
# Chunk 3
# date as character (otherwise it won't bind)
zuhause$Date <- as.character(zuhause$Date)
# combine
zh <- rbind(mutate(zuhause, variant = "zuhause"),
mutate(Zuhause, variant = "Zuhause"),
mutate(zu_Hause, variant = "zu Hause"))
# Chunk 4
zh[which(zh$Hit=="zu"),]$Hit <- "zu Hause"
zh[which(zh$Hit=="zu Hause"),]$ContextAfter <- gsub("^Hause ", "", zh[which(zh$Hit=="zu Hause"),]$ContextAfter)
# Chunk 5
# Coronacorpus URLs
urls <- read_csv("coronakorpus_urls_all.csv")
# remove duplicates
urls <- urls[-which(duplicated(urls)),]
# detect URLs that are assigned to more than 1 category
urls_dup <- urls[which(duplicated(urls$url)),]$url
urls$duplicated <- character(nrow(urls))
urls[which(urls$url %in% urls_dup),]$duplicated <- "y"
urls[which(!urls$url %in% urls_dup),]$duplicated <- "n"
for(i in 1:length(urls_dup)) {
urls[which(urls$url==urls_dup[i]),]$category <- paste0(urls[which(urls$url==urls_dup[i]),]$category, collapse = "/")
}
# remove duplicates
urls <- urls[-which(duplicated(urls$url)),]
# join dataframes
zh <- left_join(zh, urls, by = c("URL" = "url"))
# Chunk 6
# frequency of variant by Year/Month
zh1 <- zh %>% group_by(YM, variant) %>% summarise(
n = n()
)
# total frequency by Year/Month
zh2 <- zh %>% group_by(YM) %>% summarise(
n_all = n()
)
# combine both
zh_tbl <- left_join(zh1, zh2)
# add relative frequency
zh_tbl$rel <- zh_tbl$n / zh_tbl$n_all
# omit all before 2020
zh_tbl <- zh_tbl[grepl("2020|2021", zh_tbl$YM),]
# plot
zh_tbl %>% ggplot(aes (x = YM, y = rel, group = variant, col = variant)) +
geom_line(lwd = 1.2) + scale_y_continuous(labels = scales::percent) + theme_bw() + theme(axis.text.x = element_text(angle=45, hjust=.9, size=12)) + xlab("Month") + ylab("Relative Frequency") +
guides(col = guide_legend(title = "Variant"))
# Chunk 7
table(zh$Hit) %>% as.data.frame() %>% rename("Variant" = "Var1") %>% kbl()
# Chunk 8
zh$first_right <- first_right(zh, "ContextAfter", n = 1)
zh$last_left   <- last_left(zh, "ContextBefore", n = 1)
# Chunk 9
# get list of types in last_left and first_right columns
zh_last_left_first_right_types <- unique(c(zh$last_left, zh$first_right))
# run treetagger over those types
zh_last_left_first_right_types_tagged <- treetag(zh_last_left_first_right_types,
treetagger = "manual",
TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
preset = "de"), lang = "de", format = "obj")
# transform to dataframe
zh_last_left_first_right_types_tagged <- tibble(
token = as.character(zh_last_left_first_right_types_tagged@tokens$token),
pos   = as.character(zh_last_left_first_right_types_tagged@tokens$wclass)
)
# remove duplicates
if(any(duplicated(zh_last_left_first_right_types_tagged$token))) {
zh_last_left_first_right_types_tagged <- zh_last_left_first_right_types_tagged[-(which(duplicated(zh_last_left_first_right_types_tagged$token))),]
}
# rename column
zh_last_left_first_right_types_tagged <- rename(zh_last_left_first_right_types_tagged, c("LastLeftPOS" = "pos"))
# add to existing dataframe: left
zh <- left_join(zh, zh_last_left_first_right_types_tagged, by = c("last_left" = "token"), all.x = T)
# rename column
zh_last_left_first_right_types_tagged <- rename(zh_last_left_first_right_types_tagged, c("FirstRightPOS" = "LastLeftPOS"))
# add to existing dataframe: right
zh <- left_join(zh, zh_last_left_first_right_types_tagged, by = c("first_right" = "token"), all.x = T)
# export left andright context for tagging
# pbsapply(1:nrow(zh), function(i) write.table(zh$ContextBefore[i], file = paste0("tmp/", i, ".txt"), quote = F, row.names = F, col.names = F))
#
# pbsapply(1:10, function(i) paste0(as.character(treetag(zh$ContextBefore[i],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass), collapse = " "))
# paste0(as.character(treetag(zh$ContextBefore[1],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass), collapse = " ")
# pbsapply(1:nrow(zh), function(i) treetag(zh$last_left[i],
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")@tokens$wclass)
# zh_left_tags <- treetag(zh$last_left,
#               treetagger = "manual",
#               TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
#                                 preset = "de"), lang = "de", format = "obj")
# Chunk 10
# new column: "cxn" for "construction"
zh$cxn <- character(nrow(zh))
# von zu Hause
zh[which(zh$last_left=="von"),]$cxn <- "von zh"
# zu Hause zu V-en
zh[which(zh$first_right=="zu" & zh$cxn == ""),]$cxn <- "zh zu v"
# zu Hause sein
zh[which(zh$first_right %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart") | zh$last_left %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart")),]$cxn <- "zh sein"
# zh einsperren / eingesperrt
zh[grep("ein(ge)?sperr.*", zh$last_left),]$cxn <- "zh EINSPERR"
zh[grep("ein(ge)?sperr.*", zh$first_right),]$cxn <- "zh EINSPERR"
# zh verbringen
zh[grep("verbring|verbrach", zh$first_right),]$cxn <- "zh verbringen"
zh[grep("verbring|verbrach", zh$last_left),]$cxn <- "zh verbringen"
# das (eigene) Zuhause
zh[which(zh$last_left %in% c("das", "dem", "ein", "einem")),]$cxn <- "ART zh"
zh[which(last_left(zh, "ContextBefore", n = 2) %in% c("das eigene", "dem eigenen", "ein eigenes", "einem eigenen")),]$cxn <- "ART eigene zh"
# PRONOUN (demonstrative/possessive & quantifiers) + Zuhause
zh[which(zh$last_left %in% c("Ihr", "ihr", "sein", "dein", "mein", "unser", "euer", "seinem", "unserem", "keinem", "dieses", "dessen", "Ihrem", "ihrem", "kein", "keinem", "manches", "mehrere", "meinem")),]$cxn <- "PRONOUN zh"
# zh in Quarantäne
zh[which(first_right(zh, "ContextAfter", n = 2) == "in Quarantäne"),]$cxn <- "zh in Quarantäne"
# für zh
zh[which(zh$last_left == "für"),]$cxn <- "für zh"
# zh arbeiten
zh[grep("arbeit.*", zh$last_left),]$cxn <- "zh arbeiten"
zh[grep("arbeit.*", zh$first_right),]$cxn <- "zh arbeiten"
# zh bleiben
zh[grep("[Bb]leib.*", last_left(zh, "ContextBefore", n = 5)),]$cxn = "zh bleiben"
zh[grep("[Bb]leib.*", first_right(zh, "ContextAfter", n = 5)),]$cxn = "zh bleiben"
# Chunk 11: spl
set.seed(1985)
spl <- sample(1:nrow(zh), 2000)
zh$spl <- character(nrow(zh))
zh[spl,]$spl <- "in_sample"
# zh %>% write.xlsx("zh_spl.xlsx", overwrite = T)
# Chunk 12
# write.xlsx(zh, "zh.xlsx")
# Chunk 13
zh_anno <- read_xlsx("zh_spl_anno.xlsx")
# Chunk 14
zh_anno <- left_join(zh_anno, urls, by = c("URL" = "url"))
# Chunk 15
zh_anno <- filter(zh_anno, spl == "in_sample")
zh_anno <- filter(zh_anno, keep != "n")
# Chunk 16
qbarplot(zh_anno, cxn, Hit) + guides(fill = guide_legend(title = "Variant")) + theme(axis.text.x = element_text(angle=45, hjust=.9, size=12)) + xlab("Construction")
# Chunk 17
#export
# write_excel_csv(tibble(category = unique(zh$category),
#                        texttype = character(length(unique(zh$category)))),
#                 "texttypes.csv")
# re-import
texttype <- read_csv("texttypes.csv")
# bind with zh_anno
zh_anno <- left_join(zh_anno, texttype)
# Chunk 18
# convert response variable to factor
zh_anno$Hit <- factor(zh_anno$Hit)
zh_anno$cxn <- factor(zh_anno$cxn)
zh_anno$category <- factor(zh_anno$category)
zh_anno$texttype <- factor(zh_anno$texttype)
# get ctree
ct <- partykit::ctree(Hit ~ cxn + texttype, data = zh_anno)
cf <- cforest(Hit ~ cxn + texttype, data = zh_anno, controls = cforest_unbiased(mtry = 1))
# get variable importance
varimp <- varimp(cf, conditional = T)
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 6),
ip_args=list(
abbreviate = TRUE))
# random forest results: conditional variable importance
dotplot(varimp)
library(tidyverse)
library("koRpus.lang.de")
library(scales)
library(concordances)
library(pbapply)
library(readxl)
library(openxlsx)
library(kableExtra)
library(party)
library(lattice)
library(mlogit)
library(wizard)
# read data
zuhause <- read_csv("zuhause_lowercase.csv", col_types = c("d", rep("c", 7)))
Zuhause <- read_csv("Zuhause.csv")
zu_Hause <- read_csv("zu_Hause.csv", col_types = c("d", rep("c", 7)))
# add Month and Year columns
zuhause$Month <- gsub("^[0-9]{4}-|-[0-9]{2}$", "", zuhause$Date)
zuhause$Year <- gsub("-.*", "", zuhause$Date)
zuhause$YM   <- paste0(zuhause$Year, "-", zuhause$Month)
zu_Hause$Year <- gsub(".*\\.", "", zu_Hause$Date)
zu_Hause$Month <- gsub("^[0-9]{2}\\.|\\.[0-9]{4}$", "", zu_Hause$Date)
zu_Hause$YM  <- paste0(zu_Hause$Year, "-", zu_Hause$Month)
Zuhause$Month <- gsub("^[0-9]{4}-|-[0-9]{2}$", "", Zuhause$Date)
Zuhause$Year <- gsub("-.*", "", Zuhause$Date)
Zuhause$YM   <- paste0(Zuhause$Year, "-", Zuhause$Month)
# date as character (otherwise it won't bind)
zuhause$Date <- as.character(zuhause$Date)
# combine
zh <- rbind(mutate(zuhause, variant = "zuhause"),
mutate(Zuhause, variant = "Zuhause"),
mutate(zu_Hause, variant = "zu Hause"))
zh[which(zh$Hit=="zu"),]$Hit <- "zu Hause"
zh[which(zh$Hit=="zu Hause"),]$ContextAfter <- gsub("^Hause ", "", zh[which(zh$Hit=="zu Hause"),]$ContextAfter)
# Coronacorpus URLs
urls <- read_csv("coronakorpus_urls_all.csv")
# remove duplicates
urls <- urls[-which(duplicated(urls)),]
# detect URLs that are assigned to more than 1 category
urls_dup <- urls[which(duplicated(urls$url)),]$url
urls$duplicated <- character(nrow(urls))
urls[which(urls$url %in% urls_dup),]$duplicated <- "y"
urls[which(!urls$url %in% urls_dup),]$duplicated <- "n"
for(i in 1:length(urls_dup)) {
urls[which(urls$url==urls_dup[i]),]$category <- paste0(urls[which(urls$url==urls_dup[i]),]$category, collapse = "/")
}
# remove duplicates
urls <- urls[-which(duplicated(urls$url)),]
# join dataframes
zh <- left_join(zh, urls, by = c("URL" = "url"))
# frequency of variant by Year/Month
zh1 <- zh %>% group_by(YM, variant) %>% summarise(
n = n()
)
# total frequency by Year/Month
zh2 <- zh %>% group_by(YM) %>% summarise(
n_all = n()
)
# combine both
zh_tbl <- left_join(zh1, zh2)
# add relative frequency
zh_tbl$rel <- zh_tbl$n / zh_tbl$n_all
# omit all before 2020
zh_tbl <- zh_tbl[grepl("2020|2021", zh_tbl$YM),]
# plot
zh_tbl %>% ggplot(aes (x = YM, y = rel, group = variant, col = variant)) +
geom_line(lwd = 1.2) + scale_y_continuous(labels = scales::percent) + theme_bw() + theme(axis.text.x = element_text(angle=45, hjust=.9, size=12)) + xlab("Month") + ylab("Relative Frequency") +
guides(col = guide_legend(title = "Variant"))
zh$first_right <- first_right(zh, "ContextAfter", n = 1)
zh$last_left   <- last_left(zh, "ContextBefore", n = 1)
# get list of types in last_left and first_right columns
zh_last_left_first_right_types <- unique(c(zh$last_left, zh$first_right))
# run treetagger over those types
zh_last_left_first_right_types_tagged <- treetag(zh_last_left_first_right_types,
treetagger = "manual",
TT.options = list(path = "/Users/stefanhartmann/Downloads/TreeTagger/",
preset = "de"), lang = "de", format = "obj")
# transform to dataframe
zh_last_left_first_right_types_tagged <- tibble(
token = as.character(zh_last_left_first_right_types_tagged@tokens$token),
pos   = as.character(zh_last_left_first_right_types_tagged@tokens$wclass)
)
# remove duplicates
if(any(duplicated(zh_last_left_first_right_types_tagged$token))) {
zh_last_left_first_right_types_tagged <- zh_last_left_first_right_types_tagged[-(which(duplicated(zh_last_left_first_right_types_tagged$token))),]
}
# rename column
zh_last_left_first_right_types_tagged <- rename(zh_last_left_first_right_types_tagged, c("LastLeftPOS" = "pos"))
# add to existing dataframe: left
zh <- left_join(zh, zh_last_left_first_right_types_tagged, by = c("last_left" = "token"), all.x = T)
# rename column
zh_last_left_first_right_types_tagged <- rename(zh_last_left_first_right_types_tagged, c("FirstRightPOS" = "LastLeftPOS"))
# add to existing dataframe: right
zh <- left_join(zh, zh_last_left_first_right_types_tagged, by = c("first_right" = "token"), all.x = T)
# new column: "cxn" for "construction"
zh$cxn <- character(nrow(zh))
# von zu Hause
zh[which(zh$last_left=="von"),]$cxn <- "von zh"
# zu Hause zu V-en
zh[which(zh$first_right=="zu" & zh$cxn == ""),]$cxn <- "zh zu v"
# zu Hause sein
zh[which(zh$first_right %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart") | zh$last_left %in% c("sein", "bin", "bist", "ist", "seid", "sind", "war", "warst", "waren", "wart")),]$cxn <- "zh sein"
# zh einsperren / eingesperrt
zh[grep("ein(ge)?sperr.*", zh$last_left),]$cxn <- "zh EINSPERR"
zh[grep("ein(ge)?sperr.*", zh$first_right),]$cxn <- "zh EINSPERR"
# zh verbringen
zh[grep("verbring|verbrach", zh$first_right),]$cxn <- "zh verbringen"
zh[grep("verbring|verbrach", zh$last_left),]$cxn <- "zh verbringen"
# das (eigene) Zuhause
zh[which(zh$last_left %in% c("das", "dem", "ein", "einem")),]$cxn <- "ART zh"
zh[which(last_left(zh, "ContextBefore", n = 2) %in% c("das eigene", "dem eigenen", "ein eigenes", "einem eigenen")),]$cxn <- "ART eigene zh"
# PRONOUN (demonstrative/possessive & quantifiers) + Zuhause
zh[which(zh$last_left %in% c("Ihr", "ihr", "sein", "dein", "mein", "unser", "euer", "seinem", "unserem", "keinem", "dieses", "dessen", "Ihrem", "ihrem", "kein", "keinem", "manches", "mehrere", "meinem")),]$cxn <- "PRONOUN zh"
# zh in Quarantäne
zh[which(first_right(zh, "ContextAfter", n = 2) == "in Quarantäne"),]$cxn <- "zh in Quarantäne"
# für zh
zh[which(zh$last_left == "für"),]$cxn <- "für zh"
# zh arbeiten
zh[grep("arbeit.*", zh$last_left),]$cxn <- "zh arbeiten"
zh[grep("arbeit.*", zh$first_right),]$cxn <- "zh arbeiten"
# zh bleiben
zh[grep("[Bb]leib.*", last_left(zh, "ContextBefore", n = 5)),]$cxn = "zh bleiben"
zh[grep("[Bb]leib.*", first_right(zh, "ContextAfter", n = 5)),]$cxn = "zh bleiben"
set.seed(1985)
spl <- sample(1:nrow(zh), 2000)
zh$spl <- character(nrow(zh))
zh[spl,]$spl <- "in_sample"
zh_anno <- read_xlsx("zh_spl_anno.xlsx")
zh_anno <- left_join(zh_anno, urls, by = c("URL" = "url"))
zh_anno <- filter(zh_anno, spl == "in_sample")
zh_anno <- filter(zh_anno, keep != "n")
qbarplot(zh_anno, cxn, Hit) + guides(fill = guide_legend(title = "Variant")) + theme(axis.text.x = element_text(angle=45, hjust=.9, size=12)) + xlab("Construction")
# re-import
texttype <- read_csv("texttypes.csv")
# bind with zh_anno
zh_anno <- left_join(zh_anno, texttype)
# convert response variable to factor
zh_anno$Hit <- factor(zh_anno$Hit)
zh_anno$cxn <- factor(zh_anno$cxn)
zh_anno$category <- factor(zh_anno$category)
zh_anno$texttype <- factor(zh_anno$texttype)
# get ctree
ct <- partykit::ctree(Hit ~ cxn + texttype, data = zh_anno)
cf <- cforest(Hit ~ cxn + texttype, data = zh_anno, controls = cforest_unbiased(mtry = 1))
# get variable importance
varimp <- varimp(cf, conditional = T)
# plot conditional inference tree
plot(ct, gp = gpar(fontsize = 12),
ep_args = list(justmin = 6),
ip_args=list(
abbreviate = FALSE))
1728/3
1080/3
rm(list=ls())
